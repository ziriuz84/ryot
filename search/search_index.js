var __index = {"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"Installation","text":"<p>Info</p> <p>The first user you register is automatically set as admin of the instance.</p> <p>The docker image is <code>ghcr.io/ignisda/ryot:latest</code>.</p> <pre><code>services:\nryot-db:\nimage: postgres:16-alpine # atleast version 15 is required\nrestart: unless-stopped\nvolumes:\n- postgres_storage:/var/lib/postgresql/data\nenvironment:\n- POSTGRES_PASSWORD=postgres\n- POSTGRES_USER=postgres\n- POSTGRES_DB=postgres\ncontainer_name: ryot-db\n\nryot:\nimage: ghcr.io/ignisda/ryot:latest\nenvironment:\n- DATABASE_URL=postgres://postgres:postgres@ryot-db:5432/postgres\n# - FRONTEND_INSECURE_COOKIES=true # if running on HTTP\nports:\n- \"8000:8000\"\npull_policy: always\ncontainer_name: ryot\n\nvolumes:\npostgres_storage:\n</code></pre>"},{"location":"architecture.html","title":"Architecture","text":"<p>The frontend is a Remix app, the backend is an Axum server. All these run behind a Caddy reverse proxy and are managed by <code>concurrently</code>.</p>"},{"location":"architecture.html#releases","title":"Releases","text":"<p>Each version of Ryot is released as a docker image. Then it is associated with the latest Github release of the major version. For example, if the latest tag is <code>v5.2.1</code>, then the Github release will be called <code>Version 5</code> and the docker image will be tagged as <code>:v5.2.1</code> and <code>:latest</code>.</p>"},{"location":"architecture.html#development","title":"Development","text":"<p>There is a devcontainer configuration in the repository. You can use it to launch a development environment with all tools installed.</p>"},{"location":"architecture.html#environment","title":"Environment","text":"<p>In development, both servers are started independently running on <code>:3000</code> and <code>:5000</code> respectively and reverse proxied at <code>:8000</code>. To get them running, install mprocs, and run <code>mprocs</code> in the project root.</p> <p>I also recommend the following environment file:</p> .env<pre><code>DATABASE_URL=postgres://postgres:postgres@postgres:5432/postgres\nRUST_LOG=ryot=trace,sea_orm=debug\n</code></pre> <p>Your website would be available at <code>http://localhost:8000</code>.</p>"},{"location":"architecture.html#miscellaneous","title":"Miscellaneous","text":"<p>You can use Serveo to test webhooks.</p> <pre><code>ssh -R ryot:80:0.0.0.0:8000 serveo.net\n</code></pre> <p>This will expose your local server on <code>https://ryot.serveo.net</code>. You can use this URL in Jellyfin etc. to test events sent to your local Ryot instance.</p> <p>Another helpful tool is Webhook.site. It can be used to inspect the requests sent to your server.</p>"},{"location":"configuration.html","title":"Configuration","text":"<p>You can specify configuration options via environment variables or via files (loaded from <code>config/ryot.json</code>, <code>config/ryot.toml</code>, <code>config/ryot.yaml</code>). They should be present in <code>/home/ryot/config/ryot.&lt;ext&gt;</code>.</p> <p>Ryot serves the final configuration loaded at the <code>/backend/config</code> endpoint as JSON (example). This can also be treated as a health endpoint.</p> <p>Info</p> <p>The defaults can be inspected in the config builder.</p>"},{"location":"configuration.html#important-parameters","title":"Important parameters","text":"Key / Environment variable Description - / <code>PORT</code> The port to listen on. Defaults to <code>8000</code>. - / <code>TZ</code> Timezone to be used for cron jobs. Accepts values according to the IANA database. Defaults to <code>GMT</code>. - / <code>FRONTEND_INSECURE_COOKIES</code> Whether to set <code>Secure=false</code> on cookies. Set this to <code>true</code> when running in a non-https context. Defaults to <code>false</code>. <code>disable_telemetry</code> / <code>DISABLE_TELEMETRY</code> Disables telemetry collection using Umami. Defaults to <code>false</code>. <code>database.url</code> / <code>DATABASE_URL</code> The Postgres database connection string. <code>video_games.twitch.client_id</code> / <code>VIDEO_GAMES_TWITCH_CLIENT_ID</code> The client ID issued by Twitch. Required to enable video games tracking. More information <code>video_games.twitch.client_secret</code> / <code>VIDEO_GAMES_TWITCH_CLIENT_SECRET</code> The client secret issued by Twitch. Required to enable video games tracking."},{"location":"configuration.html#all-parameters","title":"All parameters","text":"<pre><code># Settings related to anime and manga.\nanime_and_manga:\n# Settings related to Anilist.\nanilist:\n# Whether to prefer the english name for media from this source.\n# @envvar ANIME_AND_MANGA_ANILIST_PREFER_ENGLISH\nprefer_english: false\n\n# Settings related to MAL.\nmal:\n# The client ID to be used for the MAL API.\n# @envvar ANIME_AND_MANGA_MAL_CLIENT_ID\nclient_id: \"\"\n\n# Settings related to MangaUpdates.\nmanga_updates: {}\n\n# Settings related to audio books.\naudio_books:\n# Settings related to Audible.\naudible:\n# Settings related to locale for making requests Audible.\n# @envvar AUDIO_BOOKS_AUDIBLE_LOCALE\nlocale: \"us\"\n\n# Settings related to books.\nbooks:\n# Settings related to Google Books.\ngoogle_books:\n# Whether to pass the raw query string to the search API.\n# @envvar BOOKS_GOOGLE_BOOKS_PASS_RAW_QUERY\npass_raw_query: false\n\n# Settings related to Openlibrary.\nopenlibrary:\n# The image sizes to fetch from Openlibrary.\n# @envvar BOOKS_OPENLIBRARY_COVER_IMAGE_SIZE\ncover_image_size: \"M\"\n\n# The database related settings.\ndatabase:\n# The Postgres database connection string.\n# Format described in https://www.sea-ql.org/SeaORM/docs/install-and-config/connection/#postgres.\n# @envvar DATABASE_URL\nurl: \"\"\n\n# Whether to disable telemetry.\n# @envvar DISABLE_TELEMETRY\ndisable_telemetry: false\n\n# Settings related to exercises.\nexercise: {}\n\n# Settings related to file storage.\nfile_storage:\n# The access key ID for the S3 compatible file storage. **Required** to\n# enable file storage.\n# @envvar FILE_STORAGE_S3_ACCESS_KEY_ID\ns3_access_key_id: \"\"\n\n# The name of the S3 compatible bucket. **Required** to enable file storage.\n# @envvar FILE_STORAGE_S3_BUCKET_NAME\ns3_bucket_name: \"\"\n\n# The region for the S3 compatible file storage.\n# @envvar FILE_STORAGE_S3_REGION\ns3_region: \"us-east-1\"\n\n# The secret access key for the S3 compatible file storage. **Required**\n# to enable file storage.\n# @envvar FILE_STORAGE_S3_SECRET_ACCESS_KEY\ns3_secret_access_key: \"\"\n\n# The URL for the S3 compatible file storage.\n# @envvar FILE_STORAGE_S3_URL\ns3_url: \"\"\n\n# Settings related to frontend storage.\nfrontend:\n# Whether the cookies set are insecure.\n# @envvar FRONTEND_INSECURE_COOKIES\ninsecure_cookies: false\n\n# The number of items to display in a list view.\n# @envvar FRONTEND_PAGE_SIZE\npage_size: 20\n\n# Settings related to Umami analytics.\numami:\n# @envvar FRONTEND_UMAMI_DOMAINS\ndomains: \"\"\n\n# For example: https://umami.is/script.js.\n# @envvar FRONTEND_UMAMI_SCRIPT_URL\nscript_url: \"\"\n\n# @envvar FRONTEND_UMAMI_WEBSITE_ID\nwebsite_id: \"\"\n\n# Used as the base URL when generating item links for the frontend.\n# @envvar FRONTEND_URL\nurl: \"https://app.ryot.io\"\n\n# Settings related to external integrations.\nintegration:\n# The salt used to hash user IDs.\n# @envvar INTEGRATION_HASHER_SALT\nhasher_salt: \"\"\n\n# The maximum progress limit after which a media is considered to be completed.\n# @envvar INTEGRATION_MAXIMUM_PROGRESS_LIMIT\nmaximum_progress_limit: 95\n\n# The minimum progress limit after which a media is considered to be started.\n# @envvar INTEGRATION_MINIMUM_PROGRESS_LIMIT\nminimum_progress_limit: 2\n\n# Sync data from [yank](/docs/guides/integrations.md) based integrations\n# every `n` hours.\n# @envvar INTEGRATION_PULL_EVERY\npull_every: 2\n\n# Settings related to media.\nmedia:\n# Number of days after which a media should be removed from the Monitoring collection.\n# @envvar MEDIA_MONITORING_REMOVE_AFTER_DAYS\nmonitoring_remove_after_days: 30\n\n# Settings related to movies and shows.\nmovies_and_shows:\n# Settings related to TMDB.\ntmdb:\n# The access token for the TMDB API.\n# @envvar MOVIES_AND_SHOWS_TMDB_ACCESS_TOKEN\naccess_token: \"\"\n\n# The locale to use for making requests to TMDB API.\n# @envvar MOVIES_AND_SHOWS_TMDB_LOCALE\nlocale: \"en\"\n\n# Settings related to podcasts.\npodcasts:\n# Settings related to iTunes.\nitunes:\n# The locale to use for making requests to iTunes API.\n# @envvar PODCASTS_ITUNES_LOCALE\nlocale: \"en_us\"\n\n# Settings related to Listennotes.\nlistennotes:\n# The access token for the Listennotes API.\n# @envvar PODCASTS_LISTENNOTES_API_TOKEN\napi_token: \"\"\n\n# Settings related to scheduler.\nscheduler:\n# The url to the SQLite database where job related data needs to be stored.\n# @envvar SCHEDULER_DATABASE_URL\ndatabase_url: \"sqlite::memory:\"\n\n# The number of jobs to process every 5 seconds when updating metadata in\n# the background.\n# @envvar SCHEDULER_RATE_LIMIT_NUM\nrate_limit_num: 5\n\n# Deploy a job every x hours that performs user cleanup and summary\n# calculation.\n# @envvar SCHEDULER_USER_CLEANUP_EVERY\nuser_cleanup_every: 12\n\n# Settings related to server.\nserver:\n# The path where the config file will be written once the server boots up.\n# @envvar SERVER_CONFIG_DUMP_PATH\nconfig_dump_path: \"\"\n\n# An array of URLs for CORS.\n# @envvar SERVER_CORS_ORIGINS\ncors_origins: []\n\n# Disable all background jobs.\n# @envvar SERVER_DISABLE_BACKGROUND_JOBS\ndisable_background_jobs: false\n\n# Whether the graphql playground will be enabled.\n# @envvar SERVER_GRAPHQL_PLAYGROUND_ENABLED\ngraphql_playground_enabled: true\n\n# The maximum file size in MB for user uploads.\n# @envvar SERVER_MAX_FILE_SIZE\nmax_file_size: 70\n\n# The OIDC related settings.\noidc:\n# @envvar SERVER_OIDC_CLIENT_ID\nclient_id: \"\"\n\n# @envvar SERVER_OIDC_CLIENT_SECRET\nclient_secret: \"\"\n\n# @envvar SERVER_OIDC_ISSUER_URL\nissuer_url: \"\"\n\n# The hours in which a media can be marked as seen again for a user. This\n# is used so that the same media can not be used marked as started when\n# it has been already marked as seen in the last `n` hours.\n# @envvar SERVER_PROGRESS_UPDATE_THRESHOLD\nprogress_update_threshold: 2\n\n# The mailer related settings.\nsmtp:\n# @envvar SERVER_SMTP_MAILBOX\nmailbox: \"Ryot &lt;no-reply@mailer.io&gt;\"\n\n# @envvar SERVER_SMTP_PASSWORD\npassword: \"\"\n\n# @envvar SERVER_SMTP_PORT\nport: 587\n\n# @envvar SERVER_SMTP_SERVER\nserver: \"\"\n\n# @envvar SERVER_SMTP_USER\nuser: \"\"\n\n# Settings related to users.\nusers:\n# Whether new users will be allowed to sign up to this instance.\n# @envvar USERS_ALLOW_REGISTRATION\nallow_registration: true\n\n# Whether to disable local user authentication completely.\n# @envvar USERS_DISABLE_LOCAL_AUTH\ndisable_local_auth: false\n\n# The secret used for generating JWT tokens.\n# @envvar USERS_JWT_SECRET\njwt_secret: \"\"\n\n# The number of days till login authentication token is valid.\n# @envvar USERS_TOKEN_VALID_FOR_DAYS\ntoken_valid_for_days: 90\n\n# Settings related to video games.\nvideo_games:\n# Settings related to IGDB.\nigdb:\n# The image sizes to fetch from IGDB.\n# @envvar VIDEO_GAMES_IGDB_IMAGE_SIZE\nimage_size: \"t_original\"\n\n# Settings related to Twitch.\ntwitch:\n# The client ID issues by Twitch. **Required** to enable video games\n# tracking. [More information](/docs/guides/video-games.md).\n# @envvar VIDEO_GAMES_TWITCH_CLIENT_ID\nclient_id: \"\"\n\n# The client secret issued by Twitch. **Required** to enable video games\n# tracking.\n# @envvar VIDEO_GAMES_TWITCH_CLIENT_SECRET\nclient_secret: \"\"\n\n# Settings related to visual novels.\nvisual_novels: {}\n</code></pre>"},{"location":"deployment.html","title":"Deployment","text":"<p>The easiest way to deploy Ryot is using the docker compose. Here is a non-exhaustive set of guides to deploy Ryot to alternative platforms.</p>"},{"location":"deployment.html#railway","title":"Railway","text":"<ol> <li>Click on \"+ New Project\" on your dashboard and select \"Empty project\".</li> <li>Once the project is created click on \"+ New\" and select \"Database\" and then   \"Add PostgreSQL\".</li> <li>Click on \"+ New\" again and select \"Docker Image\". Type <code>ghcr.io/ignisda/ryot</code>   and hit Enter.</li> <li>Click on the newly created service and go to the \"Variables\" section. Click on   \"New Variable\" and then \"Add Reference\". Click on \"Add\".</li> <li>Go to the \"Settings\" tab and then click on \"Generate Domain\".</li> <li>Optionally, you can set the healthcheck   path to <code>/backend/config</code>.</li> </ol>"},{"location":"deployment.html#dokku","title":"Dokku","text":"<p>This is a script that automatically sets up a Ryot server using the docker image uploaded to Ghcr and creates a Dokku app. The script assumes you have a global domain set-up (i.e. the file <code>/home/dokku/VHOST</code> exists). It needs to be run with <code>sudo</code> privileges.</p> <p>Re-running it updates the running server to the latest version.</p> <pre><code>#!/usr/bin/env bash\n\nset -euo pipefail\n\nif [ \"$EUID\" -ne 0 ]\nthen echo \"Please run as root\"\nexit\nfi\n\nIMAGE_NAME=\"ghcr.io/ignisda/ryot\"\nAPPNAME=\"\"\n\nread -rp \"Enter the name of the app: \" APPNAME\n\n# check if app name is empty\nif [ -z \"$APPNAME\" ]; then\necho \"App name empty. Using default name: ryot\"\nAPPNAME=\"ryot\"\nfi\n\n# pull the latest image\ndocker rmi -f \"$IMAGE_NAME\" || true\ndocker pull \"$IMAGE_NAME:latest\"\nimage_sha=\"$(docker inspect --format=\"{{index .RepoDigests 0}}\" $IMAGE_NAME)\"\necho \"Calculated image sha: $image_sha\"\n\nif dokku apps:exists $APPNAME; then\ndokku git:from-image $APPNAME $image_sha || echo \"Already on latest\"\nexit 0\nfi\n\ndokku apps:create \"$APPNAME\"\ndokku postgres:create \"$APPNAME-service\"\ndokku postgres:link \"$APPNAME-service\" \"$APPNAME\"\n\n# check if required dokku plugin exists\nif ! dokku plugin:list | grep letsencrypt; then\ndokku plugin:install https://github.com/dokku/dokku-letsencrypt.git\nfi\n\ndokku domains:add $APPNAME $APPNAME.\"$(cat /home/dokku/VHOST)\"\ndokku letsencrypt:enable \"$APPNAME\"\ndokku git:from-image \"$APPNAME\" \"$image_sha\"\n</code></pre>"},{"location":"deployment.html#fly","title":"Fly","text":"<p>The demo Ryot instance is deployed to Fly. The following steps are required to deploy to Fly.</p> <ol> <li> <p>Create a new postgres database for Ryot.    <pre><code>flyctl postgres create ryot-db\n</code></pre></p> </li> <li> <p>Copy the <code>fly.toml</code> file from this    repository to your own repository. You WILL have to change the <code>app</code> key to    a unique name. Deploy it using the below command.    <pre><code>flyctl launch\n</code></pre></p> </li> <li> <p>Connect the database.    <pre><code>fly postgres attach --app ryot ryot-db\n</code></pre></p> </li> <li> <p>Optionally you can configure the instance using <code>fly secrets set</code>.    <pre><code>fly secrets set FILE_STORAGE_S3_URL='https://play.min.io:9000'\n</code></pre></p> </li> </ol>"},{"location":"deployment.html#cosmos","title":"Cosmos","text":"<p>You can install <code>ryot</code> from the Cosmos marketplace using this link: Install Ryot or by searching for <code>Ryot</code> in the marketplace.</p> <p>Review the installation summary and click install to proceed. The database and credentials will be automatically created for you, but make sure you are happy with the URL chosen.</p> <p>The instance will be available under your newly created URL via HTTPS if it is enabled. You can then proceed with creating your first user via the web interface's registration page.</p>"},{"location":"importing.html","title":"Importing","text":"<p>Importing is meant to be a one-time operation. They are irreversible. Ryot supports importing media from a number of sources. I recommend you make a database backup before starting an import. To start, click on \"Imports and Exports\" link under the \"Settings\" section in the sidebar.</p> <p>An import can fail at various steps. Ryot creates a report when an import completes/fails. You can see the reports under \"Import History\" of the imports page.</p>"},{"location":"importing.html#notes","title":"Notes","text":"<ul> <li>Imports are very difficult to have 100% success rate. Though we try our best,   you might have to manually import some data from your previous provider.</li> <li>You can see description of the importing steps by going to <code>&lt;your instance   url&gt;/backend/graphql</code>, and then searching for <code>ImportFailStep</code> enum in search bar.</li> <li>I recommend turning on debug logging for the duration of the import using the   <code>RUST_LOG=ryot=debug</code> environment variable. This will help you help you see import   progress in the docker logs.</li> </ul>"},{"location":"importing.html#goodreads","title":"Goodreads","text":"<p>Ryot translates Goodreads shelves in the following manner:</p> <ul> <li>Want To Read -&gt; Watchlist</li> </ul>"},{"location":"importing.html#steps","title":"Steps","text":"<ul> <li>Login to your Goodreads account and go to the \"My Books\" section.</li> <li>Click on \"Import and export\" on the left sidebar.</li> <li>Click on \"Export Library\" and download the CSV file.</li> <li>Upload this file in the input.</li> </ul>"},{"location":"importing.html#mediatracker","title":"MediaTracker","text":"<p>You can import from MediaTracker, with the following caveats:</p> <ul> <li>Items that are in progress are always imported with 100% progress. They are   added to the \"In Progress\" collection so you can manually fix their progress   if needed.</li> </ul>"},{"location":"importing.html#steps_1","title":"Steps","text":"<ul> <li>Login to your MediaTracker account and click on your name on the top right.</li> <li>Click on the \"Application tokens\" section.</li> <li>Enter a name and click on \"Add token\".</li> <li>Copy the token that was just generated.</li> <li>Enter the details in the inputs.</li> </ul>"},{"location":"importing.html#movary","title":"Movary","text":"<p>The Watchlist and all movies can be imported from Movary along with ratings, history, and comments.</p>"},{"location":"importing.html#steps_2","title":"Steps","text":"<ul> <li>Login to your Movary account and go to the settings page. Go to \"Personal data\"   under the \"Account\" section.</li> <li>Export \"history.csv\", \"watchlist.csv\" and \"ratings.csv\".</li> <li>Upload these files in the input.</li> </ul>"},{"location":"importing.html#myanimelist","title":"MyAnimeList","text":"<p>Manga and Anime can be imported from MyAnimeList along with ratings, history and progress.</p>"},{"location":"importing.html#steps_3","title":"Steps","text":"<ul> <li>Login to your MyAnimeList account and go to   exports.</li> <li>Export your anime and manga history.</li> <li>Upload these files in the input.</li> </ul>"},{"location":"importing.html#storygraph","title":"StoryGraph","text":"<p>Imports from StoryGraph work using ISBN. All books in your export that have an ISBN attached to them will be imported. Ryot translates \"Read Status\" in the following manner:</p> <ul> <li>to-read -&gt; Watchlist</li> </ul>"},{"location":"importing.html#steps_4","title":"Steps","text":"<ul> <li>Login to your account and click on your profile and go to the \"Manage Account\"   page.</li> <li>Scroll to the bottom and click on \"Export StoryGraph Library\" and then   \"Generate export\".</li> <li>Once the export is done, you will receive an email. refresh the page above and   download the CSV file.</li> <li>Optionally, you can edit the CSV file and manually add the missing ISBN.</li> <li>Upload this file in the input.</li> </ul>"},{"location":"importing.html#strong-app","title":"Strong App","text":"<p>You can import your completed workouts from Strong app. Make sure you do the import process on a desktop/laptop since the process needs to have multiple tabs open at once.</p> <p>There is also an automated script that will be able to migrate most of your data. Please follow this guide.</p>"},{"location":"importing.html#steps_5","title":"Steps","text":"<ul> <li>Login to your Strong account on the app and go to the \"Settings\" page.</li> <li>Scroll down to the \"General\" section and click on \"Export data\".</li> <li>Send the file to your desktop/laptop and upload it in the input.</li> <li>The mapping section is used to map exercises from Strong to Ryot. Each exercise must be   mapped, otherwise the import will fail.</li> <li>If an exercise does not exist in your instance, you need to create it before mapping it.</li> <li>Once you have mapped all the exercises, click on \"Import\".</li> </ul>"},{"location":"importing.html#trakt","title":"Trakt","text":"<p>All movies and shows can be imported from Trakt along with their ratings, history, comments and lists. A few points to note.</p> <ul> <li>It is necessary to set your account's privacy to public during the   duration of the import. The Trakt authentication flow is pretty complicated   and I don't think it would be worth implementing.</li> <li>Items that have been \"check(ed) in\" will not be imported.</li> </ul>"},{"location":"importing.html#steps_6","title":"Steps","text":"<ul> <li>Login to your Trakt account and go to the settings page.</li> <li>If your account is set to private, uncheck the box next to it. You can revert   this change once the import is complete.</li> <li>If you have any lists that are private, you need to change them to public.   Otherwise they will not be imported.</li> <li>Find your profile slug. This is usually your username. You can find it by   going to your profile page, and checking the URL.</li> <li>Enter this username in the input.</li> </ul>"},{"location":"importing.html#imdb","title":"IMDb","text":"<p>You can import your watchlist from IMDb. They will be added to the \"Watchlist\" collection.</p>"},{"location":"importing.html#steps_7","title":"Steps","text":"<ul> <li>Go to your account and select your watchlist.</li> <li>Go the bottom and click on the \"Export this list\" button.</li> <li>Upload the csv file in the input.</li> </ul>"},{"location":"importing.html#audiobookshelf","title":"Audiobookshelf","text":"<p>The Audiobookshelf importer supports only audio books. If also need to import podcasts, please open an issue and wait till podcast support is added.</p> <p>Warning</p> <p>This will only import media that are already finished. Setup an   integration if you want to import media in progress.</p>"},{"location":"importing.html#steps_8","title":"Steps","text":"<ul> <li>Obtain an API token as described in the Audiobookshelf   authentication docs.</li> <li>Enter the correct details in the input.</li> </ul>"},{"location":"importing.html#tv-time","title":"TV Time","text":"<p>Warning</p> <p>This is a community maintained integration.</p> <p>All shows can be imported from TvTime at the moment using an external tool. You can find all the necessary steps here.</p>"},{"location":"importing.html#open-scale","title":"Open Scale","text":"<p>You can import your measurements from Open Scale app.</p> <p>This can be done by clicking on the three dots on the top right corner of the app, and then clicking on \"Export\". This will save a CSV file to your file system. Upload this file in the input.</p>"},{"location":"importing.html#jellyfin","title":"Jellyfin","text":"<p>You can import your watched movies from Jellyfin.</p> <p>Warning</p> <p>This will only import media that are already finished. Setup an   integration if you want to import media in progress.</p>"},{"location":"importing.html#steps_9","title":"Steps","text":"<ul> <li>Sign in as the admin of your Jellyfin server. Then go to Dashboard (under Administration)   and select API Keys (under Advanced).</li> <li>Click on the plus icon and give it a name. Copy the API key.</li> <li>Enter the correct details in the input. The username you enter should be the one whose   data you want to import.</li> </ul>"},{"location":"importing.html#generic-json","title":"Generic Json","text":"<p>The \"Generic Json\" can be used to import all possible data from a generic JSON file. The format of the JSON file should be <code>CompleteExport</code> as described in the exporting documentation.</p> <p>You can use this to export all your data from one Ryot instance and import it into another, or from a source that is not supported by Ryot.</p>"},{"location":"integrations.html","title":"Integrations","text":"<p>Integrations can be used to continuously update your media progress. They can be of two types:</p> <ul> <li>Yank: Progress data is downloaded from an externally running server at a   periodic interval.</li> <li>Sink: An external client publishes progress updates to the Ryot server.</li> </ul> <p>Info</p> <p>An item is marked as started when it has more than 2% progress and marked as completed when it has more than 95% progress. This can be changed via the <code>integration.{minimum,maximum}*</code> configuration keys.</p>"},{"location":"integrations.html#yank-plugins","title":"Yank plugins","text":"<p>For each integration you want to enable, credentials for the external server must be saved to your profile. To do so, go to the \"Settings\" tab and add a new integration under the \"Integrations\" tab.</p>"},{"location":"integrations.html#audiobookshelf","title":"Audiobookshelf","text":"<p>Warning</p> <p>This will only import media that are in progress. Perform an   import if you want to import media that are finished.</p> <p>The Audiobookshelf integration can sync all media which have a match from Audible.</p> <ol> <li>Obtain an API token as described in the Audiobookshelf    authentication docs.</li> <li>Go to your Ryot user settings and add the correct details as described in the    yank section.</li> </ol>"},{"location":"integrations.html#sink-plugins","title":"Sink plugins","text":"<p>All webhook URLs follow this format:</p> <pre><code>https://&lt;instance_url&gt;/backend/webhooks/integrations/&lt;name&gt;/&lt;slug&gt;\n# example\nhttps://app.ryot.io/backend/webhooks/integrations/plex/nBrLZdk53g--5V6T1\n</code></pre> <p>Warning</p> <p>Keep your webhook urls private to prevent abuse.</p>"},{"location":"integrations.html#jellyfin","title":"Jellyfin","text":"<p>Automatically add new Jellyin movie and show plays to Ryot. It will work for all the media that have been a valid TMDb ID attached to their metadata.</p> <p>Info</p> <p>Requires the unofficial webhook plugin to be installed and active in Jellyfin.</p> <ol> <li>Generate a slug in the integration settings page. Copy the newly generated    webhook Url.</li> <li>In the Jellyfin webhook plugin settings, add a new webhook using the    following settings:<ul> <li>Webhook Url =&gt; <code>&lt;paste_url_copied&gt;</code></li> <li>Payload format =&gt; <code>Default</code></li> <li>Listen to events only for =&gt; Choose your user</li> <li>Events =&gt; <code>Play</code>, <code>Pause</code>, <code>Resume</code>, <code>Stop</code> and <code>Progress</code></li> </ul> </li> </ol>"},{"location":"integrations.html#plex","title":"Plex","text":"<p>Automatically add Plex show and movie plays to Ryot. It will work for all the media that have been a valid TMDb ID attached to their metadata.</p> <ol> <li>Generate a slug in the integration settings page using the following settings:<ul> <li>Username =&gt; Your Plex <code>Fullname</code>. If you have no <code>Fullname</code> specified in Plex,    fallback to your Plex <code>Username</code>. This will be used to filter webhooks for the    specified Plex account only.</li> </ul> </li> <li>In your Plex Webhooks settings, add a new webhook using the following settings:<ul> <li>Webhook Url =&gt; <code>&lt;paste_url_copied&gt;</code></li> </ul> </li> </ol> <p>Warning</p> <p>Since Plex does not send the expected TMDb ID for shows, progress will only be synced if you already have the show in the Ryot database. To do this, simply add the show to your watchlist.</p>"},{"location":"integrations.html#kodi","title":"Kodi","text":"<p>The Kodi integration allows syncing the current movie or TV show you are watching. It will work for all the media that have been a valid TMDb ID attached to their metadata.</p> <ol> <li>Generate a slug in the integration settings page. Copy the newly generated    webhook Url.</li> <li>Download the addon from github releases.    The file will have a name of <code>script.ryot.zip</code>.</li> <li>Install    the zipped addon to your Kodi instance. Once installed, it will be visible under    the \"Services\" sub category named \"Ryot\".</li> <li>Click on \"Configure\" to fill in the correct details.</li> </ol>"},{"location":"integrations.html#flow-launcher","title":"Flow Launcher","text":"<p>Warning</p> <p>This is a community maintained integration.</p> <p>The plugin for Flow Launcher allows you to quickly search your Ryot tracker by media category:</p> <p></p> <p>To install, search for \"Ryot\" in the Flow Launcher plugin store. Or use <code>pm install ryot</code>.</p> <p>Refer to the documentation for post-install configuration.</p>"},{"location":"migration.html","title":"Migration","text":"<p>All steps below are required unless otherwise stated. Please follow them in the correct order.</p>"},{"location":"migration.html#from-v4-to-v5","title":"From <code>v4.*</code> to <code>v5.*</code>","text":"<p>New upgrade strategy</p> <p>Starting from <code>v5</code>, the server can be updated without any complicated steps.</p> <ol> <li> <p>Upgrade the server to <code>v4.4.3</code> to make sure all <code>v4</code> migrations are applied. For    example, you can make this change: <code>image: \"ghcr.io/ignisda/ryot:v4.4.3\"</code> in your    docker-compose file.</p> </li> <li> <p>Create a backup of your database. Here    is a guide on how to do this.</p> </li> <li> <p>Now you can upgrade to the latest version (<code>v5.*</code>). For example you can make this    change: <code>image: \"ghcr.io/ignisda/ryot:latest\"</code> in your docker-compose file. This will    automatically apply all migrations.</p> </li> </ol>"},{"location":"migration.html#from-v3-to-v4","title":"From <code>v3.*</code> to <code>v4.*</code>","text":"<p>Webhook URL changes</p> <p>If you were using Plex, Jellyfin or Kodi, all webhooks urls will now have the <code>/backend</code> prefix. Please take a look at the integration docs for the new format.</p> <ol> <li> <p>Upgrade the server to <code>v3.5.4</code> to make sure all pending migrations are applied. For example,    you can make this change: <code>image: \"ghcr.io/ignisda/ryot:v3.5.4\"</code> in your docker-compose file.</p> </li> <li> <p>Go to the \"Preferences\" settings, then the \"General\" tab, and click on \"Disable yank    integrations\" twice. This will ensure that latest preferences have been applied.</p> </li> <li> <p>Go to the \"Miscellaneous\" settings and click on \"Re-evaluate workouts\".</p> </li> <li> <p>Next, click on the button to \"Clean and regenerate\" your summary. This takes time if    you have a lot of media. Go to the dashboard and check the time under the \"Summary\"    section. It should say \"Calculated just now\".</p> </li> <li> <p>Logout and then clear the local storage and cookies for your domain.    Here    is a guide on how to do this. Uninstall the PWA if you have it installed.</p> </li> <li> <p>Create a backup of the database.</p> </li> <li> <p>Connect to the database (<code>docker exec -u postgres -it ryot-db psql</code>) and run these SQL    queries:    <pre><code>DELETE FROM seaql_migrations;\n\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20230410_create_metadata', 1684693316);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20230413_create_person', 1684693316);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20230417_create_user', 1684693316);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20230419_create_seen', 1684693316);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20230501_create_metadata_group', 1697640078);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20230502_create_genre', 1684693316);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20230504_create_collection', 1684693316);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20230505_create_review', 1684693316);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20230509_create_import_report', 1684693316);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20230622_create_exercise', 1697640078);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20230804_create_user_measurement', 1697640078);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20230819_create_workout', 1697640078);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20230901_create_partial_metadata', 1697640078);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20230912_create_calendar_event', 1697640078);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20231003_create_partial_metadata_to_person', 1697640078);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20231016_create_collection_to_entity', 1697640078);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20231017_create_user_to_entity', 1697640078);\n</code></pre></p> </li> <li> <p>Now you can upgrade to the latest version (<code>v4.*</code>) safely. For example you can make this    change: <code>image: \"ghcr.io/ignisda/ryot:latest\"</code> in your docker-compose file.</p> </li> </ol>"},{"location":"migration.html#from-v2-to-v3","title":"From <code>v2.*</code> to <code>v3.*</code>","text":"<ol> <li> <p>Upgrade the server to <code>v2.24.2</code> to make sure all pending migrations are applied.</p> </li> <li> <p>Go to the \"Miscellaneous\" settings and click on the button to \"Clean and regenerate\"    your summary. This takes time if you have a lot of media. Go to the dashboard and check    the time under the \"Summary\" section. It should say \"Calculated just now\".</p> </li> <li> <p>Go to the \"Preferences\" settings, then the \"General\" tab, and click any switch button    twice to make sure the latest settings have been applied.</p> </li> <li> <p>Stop the running server and create a backup of your database.</p> </li> <li> <p>Connect to the database and run these SQL queries:    <pre><code>DELETE FROM seaql_migrations;\n\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20230410_create_metadata', 1684693316);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20230413_create_person', 1684693316);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20230417_create_user', 1684693316);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20230419_create_seen', 1684693316);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20230502_create_genre', 1684693316);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20230505_create_review', 1684693316);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20230507_create_collection', 1684693316);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20230509_create_import_report', 1684693316);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20230622_create_exercise', 1697640078);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20230804_create_user_measurement', 1697640078);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20230819_create_workout', 1697640078);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20230901_create_metadata_group', 1697640078);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20230901_create_partial_metadata', 1697640078);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20230912_create_calendar_event', 1697640078);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20231003_create_partial_metadata_to_person', 1697640078);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20231016_create_collection_to_entity', 1697640078);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20231017_create_user_to_entity', 1697640078);\n</code></pre></p> </li> <li> <p>Now you can upgrade to the latest release safely.</p> </li> </ol>"},{"location":"migration.html#from-v1-to-v2","title":"From <code>v1.*</code> to <code>v2.*</code>","text":"<ol> <li> <p>Stop the running server and create a backup of your database.</p> </li> <li> <p>Run the last release of the server to perform all migrations (make sure to connect it to the correct database).    <pre><code>$ docker run --volume ./ryot/data:/data ghcr.io/ignisda/ryot:v1.22.1\n</code></pre></p> </li> <li> <p>Once the migrations from the above step are done, stop the server.</p> </li> <li> <p>Before upgrading to the public release, connect to the database again and run these migrations:    <pre><code>DELETE FROM seaql_migrations;\n\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20230410_create_metadata', 1684693316);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20230412_create_creator', 1684693316);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20230417_create_user', 1684693316);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20230419_create_seen', 1684693316);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20230502_create_genre', 1684693316);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20230505_create_review', 1684693316);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20230507_create_collection', 1684693316);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20230509_create_import_report', 1684693316);\n</code></pre></p> </li> <li> <p>Now you can upgrade to the latest release safely.</p> </li> <li> <p>OPTIONAL: Once you have the new server up and running, go to the \"Miscellaneous\" settings page and click on the button to \"Update All Metadata\".</p> </li> </ol>"},{"location":"guides/exporting.html","title":"Exporting","text":"<p>You need to have S3 configured in order to export your data. You can find the necessary configuration parameters under the <code>FileStorageConfig</code> section. The export will be made in JSON format and always follows the schema (<code>CompleteExport</code>) described below.</p> <p>You can export your data from the app by going to the \"Imports and Exports\" settings page and then selecting the data you want to export under the \"Export\" tab.</p> <p>Once the export is complete, it will appear along with a button to download it.</p>"},{"location":"guides/exporting.html#one-time-file-storage","title":"One time file storage","text":"<p>If you want to use file storage only for exporting, you can configure it to use a public S3 instance offered by Minio.</p> <p>Not for production use</p> <p>The Minio team resets this instance every 24 hours, hence this method is not suitable if you want to store the data for a long time.</p> <ul> <li>Go to the Minio playground. The username is <code>minioadmin</code> and   password is <code>minioadmin</code>.</li> <li>Click on \"Buckets\" under the \"Administrator\" section and then on \"Create Bucket\".</li> <li>Set a name and click on \"Create Bucket\".</li> <li>Click on \"Access Keys\" under the \"User\" section and then on \"Create access key\".</li> <li>Leave everything as it is and click on \"Create\". Copy both the values displayed.</li> <li>On your Ryot instance, set the following environment variables:     <pre><code>FILE_STORAGE_S3_URL=https://play.min.io\nFILE_STORAGE_S3_BUCKET_NAME=ryot-demo\nFILE_STORAGE_S3_ACCESS_KEY_ID=cqXhVseqa4mpqS4RLG3p\nFILE_STORAGE_S3_SECRET_ACCESS_KEY=sJxF4eZkuc4Eo6daGEFhTctzKzGbY6G6qAQTb8Wy\n</code></pre></li> <li>Restart your Ryot instance and follow the steps described in the previous section.</li> </ul>"},{"location":"guides/exporting.html#type-definition","title":"Type definition","text":"<pre><code>// Automatically generated by schematic. DO NOT MODIFY!\n\n/* eslint-disable */\n\nexport interface UserMeasurementStats {\nabdominal_skinfold: string | null;\nbasal_metabolic_rate: string | null;\nbiceps_circumference: string | null;\nbody_fat: string | null;\nbody_fat_caliper: string | null;\nbody_mass_index: string | null;\nbone_mass: string | null;\ncalories: string | null;\nchest_circumference: string | null;\nchest_skinfold: string | null;\ncustom: Record&lt;string, string&gt; | null;\nhip_circumference: string | null;\nlean_body_mass: string | null;\nmuscle: string | null;\nneck_circumference: string | null;\nthigh_circumference: string | null;\nthigh_skinfold: string | null;\ntotal_body_water: string | null;\ntotal_daily_energy_expenditure: string | null;\nvisceral_fat: string | null;\nwaist_circumference: string | null;\nwaist_to_height_ratio: string | null;\nwaist_to_hip_ratio: string | null;\nweight: string | null;\n}\n\n/** An export of a measurement taken at a point in time. */\nexport interface UserMeasurement {\n/** Any comment associated entered by the user. */\ncomment: string | null;\n/** The name given to this measurement by the user. */\nname: string | null;\n/** The contents of the actual measurement. */\nstats: UserMeasurementStats;\n/** The date and time this measurement was made. */\ntimestamp: string;\n}\n\nexport type MediaLot = 'AudioBook' | 'Anime' | 'Book' | 'Podcast' | 'Manga' | 'Movie' | 'Show' | 'VideoGame' | 'VisualNovel';\n\nexport interface IdAndNamedObject {\nid: number;\nname: string;\n}\n\n/** Comments left in replies to posted reviews. */\nexport interface ImportOrExportItemReviewComment {\ncreated_on: string;\nid: string;\n/** The user ids of all those who liked it. */\nliked_by: number[];\ntext: string;\nuser: IdAndNamedObject;\n}\n\nexport type Visibility = 'public' | 'private';\n\n/** Review data associated to a rating. */\nexport interface ImportOrExportItemReview {\n/** The date the review was posted. */\ndate: string | null;\n/** Whether to mark the review as a spoiler. Defaults to false. */\nspoiler: boolean | null;\n/** Actual text for the review. */\ntext: string | null;\n/**\n     * The visibility set by the user.\n     *\n     * @default 'public'\n     */\nvisibility: Visibility | null;\n}\n\n/** A rating given to an entity. */\nexport interface ImportOrExportItemRating {\n/** If for an anime, the episode for which this review was for. */\nanime_episode_number: number | null;\n/** The comments attached to this review. */\ncomments: ImportOrExportItemReviewComment[] | null;\n/** If for a manga, the chapter for which this review was for. */\nmanga_chapter_number: number | null;\n/** If for a podcast, the episode for which this review was for. */\npodcast_episode_number: number | null;\n/** The score of the review. */\nrating: string | null;\n/** Data about the review. */\nreview: ImportOrExportItemReview | null;\n/** If for a show, the episode for which this review was for. */\nshow_episode_number: number | null;\n/** If for a show, the season for which this review was for. */\nshow_season_number: number | null;\n}\n\n/** A specific instance when an entity was seen. */\nexport interface ImportOrExportMediaItemSeen {\n/** If for an anime, the episode which was seen. */\nanime_episode_number: number | null;\n/** The timestamp when finished watching. */\nended_on: string | null;\n/** If for a manga, the chapter which was seen. */\nmanga_chapter_number: number | null;\n/** If for a manga, the volume which was seen. */\nmanga_volume_number: number | null;\n/** If for a podcast, the episode which was seen. */\npodcast_episode_number: number | null;\n/** The progress of media done. If none, it is considered as done. */\nprogress: string | null;\n/** The provider this item was watched on. */\nprovider_watched_on: string | null;\n/** If for a show, the episode which was seen. */\nshow_episode_number: number | null;\n/** If for a show, the season which was seen. */\nshow_season_number: number | null;\n/** The timestamp when started watching. */\nstarted_on: string | null;\n}\n\nexport type MediaSource = 'Anilist' | 'Audible' | 'Custom' | 'GoogleBooks' | 'Igdb' | 'Itunes' | 'Listennotes' | 'MangaUpdates' | 'Mal' | 'Openlibrary' | 'Tmdb' | 'Vndb';\n\n/** Details about a specific media item that needs to be imported or exported. */\nexport interface ImportOrExportMediaItem {\n/** The collections this entity was added to. */\ncollections: string[];\n/** The provider identifier. For eg: TMDB-ID, Openlibrary ID and so on. */\nidentifier: string;\n/**\n     * The type of media.\n     *\n     * @default 'Book'\n     */\nlot: MediaLot;\n/** The review history for the user. */\nreviews: ImportOrExportItemRating[];\n/** The seen history for the user. */\nseen_history: ImportOrExportMediaItemSeen[];\n/**\n     * The source of media.\n     *\n     * @default 'Audible'\n     */\nsource: MediaSource;\n/** An string to help identify it in the original source. */\nsource_id: string;\n}\n\n/** Details about a specific media group item that needs to be imported or exported. */\nexport interface ImportOrExportMediaGroupItem {\n/** The collections this entity was added to. */\ncollections: string[];\n/** The provider identifier. For eg: TMDB-ID, Openlibrary ID and so on. */\nidentifier: string;\n/**\n     * The type of media.\n     *\n     * @default 'Book'\n     */\nlot: MediaLot;\n/** The review history for the user. */\nreviews: ImportOrExportItemRating[];\n/**\n     * The source of media.\n     *\n     * @default 'Audible'\n     */\nsource: MediaSource;\n/** Name of the group. */\ntitle: string;\n}\n\nexport interface PersonSourceSpecifics {\nis_anilist_studio: boolean | null;\nis_tmdb_company: boolean | null;\n}\n\n/** Details about a specific creator item that needs to be exported. */\nexport interface ImportOrExportPersonItem {\n/** The collections this entity was added to. */\ncollections: string[];\n/** The provider identifier. */\nidentifier: string;\n/** The name of the creator. */\nname: string;\n/** The review history for the user. */\nreviews: ImportOrExportItemRating[];\n/**\n     * The source of data.\n     *\n     * @default 'Audible'\n     */\nsource: MediaSource;\n/** The source specific data. */\nsource_specifics: PersonSourceSpecifics | null;\n}\n\nexport interface EntityAssets {\n/** The keys of the S3 images. */\nimages: string[];\n/** The keys of the S3 videos. */\nvideos: string[];\n}\n\nexport type ExerciseLot = 'Duration' | 'DistanceAndDuration' | 'Reps' | 'RepsAndWeight';\n\nexport type SetLot = 'Normal' | 'WarmUp' | 'Drop' | 'Failure';\n\nexport type WorkoutSetPersonalBest = 'Weight' | 'OneRm' | 'Volume' | 'Time' | 'Pace' | 'Reps';\n\nexport interface WorkoutSetStatistic {\ndistance: string | null;\nduration: string | null;\none_rm: string | null;\npace: string | null;\nreps: number | null;\nvolume: string | null;\nweight: string | null;\n}\n\nexport interface WorkoutSetTotals {\nweight: string | null;\n}\n\n/** Details about the set performed. */\nexport interface WorkoutSetRecord {\nactual_rest_time: number | null;\nconfirmed_at: string | null;\nlot: SetLot;\npersonal_bests: WorkoutSetPersonalBest[];\n/** Details about the statistics of the set performed. */\nstatistic: WorkoutSetStatistic;\ntotals: WorkoutSetTotals;\n}\n\nexport interface WorkoutOrExerciseTotals {\ndistance: string;\nduration: string;\n/** The number of personal bests achieved. */\npersonal_bests_achieved: number;\nreps: number;\n/** The total seconds that were logged in the rest timer. */\nrest_time: number;\nweight: string;\n}\n\n/** An exercise that has been processed and committed to the database. */\nexport interface ProcessedExercise {\n/** The assets that were uploaded for an entity. */\nassets: EntityAssets;\nlot: ExerciseLot;\nname: string;\nnotes: string[];\nrest_time: number | null;\nsets: WorkoutSetRecord[];\n/** The indices of the exercises with which this has been superset with. */\nsuperset_with: number[];\n/** The totals of a workout and the different bests achieved. */\ntotal: WorkoutOrExerciseTotals;\n}\n\nexport interface WorkoutInformation {\n/** The assets that were uploaded for an entity. */\nassets: EntityAssets;\nexercises: ProcessedExercise[];\n}\n\n/** The summary about an exercise done in a workout. */\nexport interface WorkoutSummaryExercise {\n/** Details about the set performed. */\nbest_set: WorkoutSetRecord;\nid: string;\nlot: ExerciseLot;\nnum_sets: number;\n}\n\nexport interface WorkoutSummary {\nexercises: WorkoutSummaryExercise[];\n/** The totals of a workout and the different bests achieved. */\ntotal: WorkoutOrExerciseTotals;\n}\n\n/** A workout that was completed by the user. */\nexport interface Workout {\ncomment: string | null;\nend_time: string;\nid: string;\n/** Information about a workout done. */\ninformation: WorkoutInformation;\nname: string;\nstart_time: string;\nsummary: WorkoutSummary;\n}\n\n/** Complete export of the user. */\nexport interface CompleteExport {\n/** Data about user's measurements. */\nmeasurements: UserMeasurement[] | null;\n/** Data about user's media. */\nmedia: ImportOrExportMediaItem[] | null;\n/** Data about user's media groups. */\nmedia_group: ImportOrExportMediaGroupItem[] | null;\n/** Data about user's people. */\npeople: ImportOrExportPersonItem[] | null;\n/** Data about user's workouts. */\nworkouts: Workout[] | null;\n}\n</code></pre>"},{"location":"guides/exporting.html#exporting-the-entire-database","title":"Exporting the entire database","text":"<p>While debugging bugs, I might ask you to send me a database dump. You can do this by exporting the entire database and emailing the file.</p> <pre><code>docker exec -u postgres -i ryot-db pg_dump -Fc --no-acl --no-owner &gt; /tmp/ryot.file.sql\n</code></pre>"},{"location":"guides/openid.html","title":"OpenID Authentication","text":"<p>Ryot can be configured to use OpenID Connect (OIDC) for authentication. The following environment variables need to be set:</p> <pre><code>FRONTEND_URL=https://app.ryot.io # The URL of your Ryot instance\nSERVER_OIDC_CLIENT_ID=********\nSERVER_OIDC_CLIENT_SECRET=********\nSERVER_OIDC_ISSUER_URL=https://accounts.google.com # The URL of your OIDC provider\n</code></pre> <p>In your OIDC provider, you will need to set the redirect URL to <code>&lt;FRONTEND_URL&gt;/api/auth</code>. The scopes required are <code>openid email</code>.</p> <p>Once these are set, restart your Ryot instance and you should be able to see the button to \"Continue with OpenID Connect\" on the authentication pages. New users will have their username set to their email address. This can be changed later in the profile settings.</p> <p>Warning</p> <p>A user can authenticate using only one provider at a time.</p> <p>You can set <code>USERS_DISABLE_LOCAL_AUTH=true</code> to disable local authentication and only allow users to authenticate using OIDC.</p>"},{"location":"guides/video-games.html","title":"Video games","text":"<p>A guide about video games integration for Ryot.</p>"},{"location":"guides/video-games.html#integration-with-igdb","title":"Integration with IGDB","text":"<p>Ryot supports tracking video games via IGDB. However, the API is heavily rate limited, so it is not possible to hardcode the API keys in the application (unlike the other keys).</p> <p>You can follow the below steps to obtain your own API keys and enable video game tracking.</p>"},{"location":"guides/video-games.html#steps","title":"Steps","text":"<ol> <li> <p>Create a Twitch account.</p> </li> <li> <p>Open your developer console.</p> </li> <li> <p>Click on \"Register Your Application\" on the dashboard.</p> </li> <li> <p>Fill up the details. Any name will suffice but it must be unique. Click on \"Create\"    when you are done.</p> </li> <li> <p>You will be guided back to your application dashboard. Click on \"Manage\" for    the application you just created.</p> </li> <li> <p>Generate a client secret. Copy the Client ID and Client Secret.</p> </li> <li> <p>Set the <code>video_games.*</code> configuration variables in the environment as    described in the configuration docs.</p> </li> </ol>"}]}